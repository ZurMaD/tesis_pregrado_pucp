@book{Berins1991,
	abstract = {I am pleased to present the Fifth Edition of the Plastics Engineering Handbook. Last published in 1976, this version of the standard industry reference on plastics processing incorporates the numerous revisions and additions necessitated by 14 years of activity in a dynamic industry. At that last printing, then-SPI President Ralph L. Harding, Jr. anticipated that plastics pro­ duction would top 26 billion pounds in 1976 (up from 1.25 billion in 1947, when the First Edition of this book was issued). As I write, plastics production in the United States had reached almost 60 billion pounds annually. Indeed, the story of the U.S. plastics industry always has been one of phenomenal growth and unparalleled innovation. While these factors make compilation of a book such as this difficult, they also make it necessary. Thus I acknowledge all those who worked to gather and relate the information included in this 1991 edition and thank them for the effort it took to make the Plastics Engineering Handbook a definitive source and invaluable tool for our industry. Larry L. Thomas President The Society of the Plastics Industry, Inc.},
	author = {Berins, Michael L.},
	file = {:C\:/Users/PabloGod/Downloads/SPI Plastics Engineering Handbook of the Society of the Plastics Industry, Inc. by Michael L. Berins (ed.) (z-lib.org).pdf:pdf},
	isbn = {978-1-4615-7604-4},
	keywords = {SPI plastics,plastic},
	mendeley-groups = {Thesis/Thesis 2},
	pages = {849},
	publisher = {Springer},
	title = {{SPI Plastics Engineering Handbook of the Society of the Plastics Industry, Inc.}},
	url = {https://www.springer.com/gp/book/9781461576068},
	year = {1991}
}
@misc{bochkovskiy2020yolov4,
	abstract = {There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets.},
	archivePrefix = {arXiv},
	arxivId = {cs.CV/2004.10934},
	author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
	eprint = {2004.10934},
	file = {:C\:/Users/PabloGod/Downloads/2004.10934.pdf:pdf},
	keywords = {Computer Vision and Pattern Recognition,computer vision,yolo,yolo segmentation,yolo v2,yolov2,yolov3,yolov4},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	mendeley-tags = {computer vision,yolo,yolo segmentation,yolo v2,yolov2,yolov3,yolov4},
	pages = {17},
	primaryClass = {cs.CV},
	title = {{YOLO v4.0: Optimal Speed and Accuracy of Object Detection}},
	url = {https://arxiv.org/abs/2004.10934},
	year = {2020}
}
@phdthesis{DiazVergara2020,
	abstract = {Este trabajo de investigaci{\'{o}}n aborda el proceso cr{\'{i}}tico de clasificaci{\'{o}}n de truchas. Actualmente, llevados a cabo de forma manual en la Laguna de Paucarcocha. Este trabajo busca reducir la mortandad y aumentar la eficiencia del proceso. Elaborar el dise{\~{n}}o conceptual de la m{\'{a}}quina que puede automatizar el proceso es primordial. Se sigue la metodolog{\'{i}}a de dise{\~{n}}o VDI. Las conclusiones detallan la selecci{\'{o}}n del mejor dise{\~{n}}o conceptual de tres propuestos.},
	author = {{D{\'{i}}az Vergara}, Pablo},
	keywords = {clasification machine,counter machine,fish,fish segmentation,trout,truchas},
	mendeley-groups = {Thesis/Thesis 2},
	mendeley-tags = {clasification machine,counter machine,fish,fish segmentation,trout,truchas},
	pages = {79},
	school = {Pontificia Universidad Cat{\'{o}}lica del Per{\'{u}}},
	title = {{Dise{\~{n}}o conceptual de clasificadora y contadora de truchas arco{\'{i}}ris (Oncorhynchus mykiss) de 10 a 20 cent{\'{i}}metros para la crianza de truchas en la Laguna de Paucarcocha}},
	year = {2020}
}
@article{Fry1970,
	abstract = {Cruising speed at 10 C of rainbow trout 4–100 g was measured in a rotating chamber and found to vary as weight 0.13 . Weight varied as length 2.91 , so that swimming speed was dependent on length 0.4 , close to the relation found for other salmonids by other authors. A 10-g fish could swim at approximately 9 body lengths (L) sec −1 whereas at 100 g the cruising speed was 5.5 L sec −1 . By extrapolation the rate at 1000 g was 3 L sec −1 .},
	author = {Fry, F. E. J. and Cox, E. T.},
	doi = {10.1139/f70-111},
	file = {:C\:/Users/PabloGod/Downloads/fry1970.pdf:pdf},
	issn = {0015-296X},
	journal = {Journal of the Fisheries Research Board of Canada},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{A Relation of Size to Swimming Speed in Rainbow Trout}},
	year = {1970}
}
@book{Harper2000,
	abstract = {State-of-the-art guide to plastic product design, manufacture and application. Edited by Charles A. Harper and sponsored by Modern Plastics, the industry's most prestigious trade magazine, Modern Plastics Handbook packs a wealth of up-to-date knowledge about plastics processes, forms and formulations, design, equipment, testing and recycling. This A-to-Z guide keeps you on top of: *Properties and performance of thermoplastics, polymer blends...thermosets, reinforced plastics and composites...natural and synthetic elastomers *Processes from extrusion, injection and blow molding to thermoforming, foam processing, hand lay-up and filament winding, and many, many more *Fabricating...post-production finishing and bonding...coatings and finishes, subjects difficult to find treated elsewhere in print *More!},
	author = {Harper, Charles A.},
	edition = {1st},
	file = {:C\:/Users/PabloGod/Downloads/Modern plastics handbook by Charles A. Harper.pdf:pdf},
	isbn = {0070267146},
	keywords = {handbook,modern plastics,plastic},
	mendeley-groups = {Thesis/Thesis 2},
	pages = {1233},
	publisher = {McGraw-Hill},
	title = {{Modern plastic handbook}},
	year = {2000}
}
@article{Mahammed2013,
	abstract = {International Journal of Science and Applied Information Technology (IJSAIT) , Vol.2 , No. 2 , Pages : 0 5 - 0 8 (2013) Special Issue of IC CTE 2013 - Held during 11 - 12 March , 2013 in Hotel Crowne Plaza, Dubai ISSN 2278 - 30 83  A BSTRACT T he 3D camera consists of two cameras of parallel optical axes and separated horizontally from each other by a small distance and these two cameras are combined together in a single frame. The 3D camera is used to produce two stereoscopic pictures for a giv en object. The distance between the cameras and the object can be measured depending upon the distance between the positions of the objects in both pictures, the focal lengths of both cameras as well as the distance. Triangulation is used to relate those m entioned dimensions with each other. Image processing is used to determine relations between the pictures of the object in the images formed by left and right camera through the technique of template matching. Template matching is used to find similarity b etween parts of the two images containing the object picture, which lead to find the amount of disparity in the object position coordinates. The distance of the object varies inversely with disparity and the accuracy of distance measurements depends on res olution of the camera pictures, lens optical properties and separation between the optical axes of both cameras. Throughout this work a 3D webcam is used and a matlab code was written to find the object distance. Four tests were executed and the measured o bject distances were 18.7654 cm, 46.3146 cm, 66.7480 cm , and 100.8809 cm. The measured distances were compared with those measured at the same time by a digital laser range finder and there were good agreement between them with percentage error ranged from 1.13% to - 2.05%},
	author = {Mahammed, Manaf A and Melhum, Amera I and Kochery, Faris A},
	file = {:C\:/Users/PabloGod/Downloads/ObjectDistanceMeasurementbyStereoVISION.pdf:pdf},
	journal = {2013 International Journal of Science and Applied Information Technology (IJSAIT)},
	keywords = {distance,stereo vision,template matching},
	mendeley-groups = {Thesis/Thesis 2},
	title = {{Object Distance Measurement by Stereo VISION}},
	year = {2013}
}
@misc{MakeItFrom2020,
	abstract = {MakeItFrom.com is a curated database of engineering material properties that emphasizes ease of comparison. It is not a datasheet dump: every listed material is an internationally recognized generic material. The data is sourced from published standards, academic literature, and supplier documentation. To find information on a particular material, browse from the list below, or search from the menu. Aside from searching by material name, you can also search by property values. Once on a material's page, you can search for a second material for a side-by-side comparison.},
	author = {MakeItFrom},
	keywords = {Material properties database},
	mendeley-groups = {Thesis/Thesis 2},
	mendeley-tags = {Material properties database},
	title = {{Material Properties Database}},
	url = {https://www.makeitfrom.com/},
	urldate = {2020-09-22},
	year = {2020}
}
@article{OatesDavidW.KringsLisaM.Ditz1993,
	abstract = {This manual is designed for use in the field to help conservation officers identify fish that have been filleted or skinned. Many North American freshwater gamefish and those caught by commercial fishermen are included. Our goal was to collect six fish of each species for measurement purposes. Several states and provinces in- cluding Alaska, Colorado, Florida, Idaho, Iowa, Michigan, Missouri, Nebraska, New York, Ontario, Saskatchewan, Texas, Virginia, Washington, Washington D.C., Wisconsin and Wyoming furnished samples. Fish may vary from loca- tion to location; these differences were not corrected for in this manual. For identification of fish, we will first examine fillets. Fish fillets, in most connotations, are of a fish skinned and cut along one side of the vertebrae. Two fillets (right and left side) are found on an individual fish (two left sides equal two fish, not one). Identification is much easier if the fish is scaled (number of scales may be counted vertically or horizontally) or if ribs are kept with the fillets. Some states and provinces require a one-inch patch of scales to be retained with each fillet. If this skin is removed, you have an illegal, unidentified fish. Some groups of fishes look so much alike that a close examination of scales or a laboratory analysis of flesh is necessary for identification. Shape of fillet, color and rib numbers can vary from species to species. Patterns on scales differ between species and can be used like human fingerprints. Many people fillet fish differently, and pieces can be fit together if necessary. Larger fillets may be cut up into smaller sections, but with smaller fish, the fillet is frequently kept whole. Can fillets be identified? Using an electrophoresis technique, some fish species have been identified by flesh alone. This can take agreat deal of time and many forensic laboratories are not equipped or able to perform this service. Very little research, except for identificationof larval fish, has examined the use of muscle segments or myotomes. A study in France by Blin, Balea and Prudhomme (1953) examined cross-sections of major fish sold at the market place. Cross-sections just behind the head (the end of sternum), at the tip of the anus and midway between anus and tail were taken. This comparison was taken for some of the fish examined and identification can be made to families. Can these fillets be identified without employing any fancy scientific equipment? For many species, the answer is yes. This manual was designed to aid in this task.},
	author = {{Oates, David W., Krings, Lisa M., Ditz}, Karen L.},
	file = {:C\:/Users/PabloGod/Downloads/fulltext.pdf:pdf},
	journal = {Other Publications in Wildlife Management. Paper 13.},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{Field Manual for the Identification of Selected North American Freshwater Fish by Fillets and Scales}},
	year = {1993}
}
@book{Pahl2007,
	abstract = {Engineering design must be carefully planned and systematically executed. In particular, engineering design methods must integrate the many different aspects of designing and the priorities of the end-user. Engineering Design (3rd edition) describes a systematic approach to engineering design. The authors argue that such an approach, applied flexibly and adapted to a particular task, is essential for successful product development. The design process is first broken down into phases and then into distinct steps, each with its own working methods. The third edition of this internationally-recognised text is enhanced with new perspectives and the latest thinking. These include extended treatment of product planning; new sections on organisation structures, simultaneous engineering, leadership and team behaviour; and updated chapters on quality methods and estimating costs. New examples have been added and existing ones extended, with additions on design to minimise wear, design for recycling, mechanical connections, mechatronics, and adaptronics.},
	address = {London},
	author = {Pahl, Gerhard and Beitz, Wolfgang and Feldhusen, J{\"{o}}rg and Grote, Karl-Heinrich},
	doi = {10.1007/978-1-84628-319-2},
	edition = {3},
	file = {:C\:/Users/PabloGod/Downloads/Engineering Design A Systematic Approach by Gerhard Pahl, Wolfgang Beitz, J{\"{o}}rg Feldhusen, Karl-Heinrich Grote, (z-lib.org).pdf:pdf},
	isbn = {978-1-84628-318-5},
	mendeley-groups = {Thesis,Thesis/Thesis1,Thesis/Thesis 2},
	pages = {617},
	publisher = {Springer London},
	title = {{Engineering Design}},
	url = {http://link.springer.com/10.1007/978-1-84628-319-2},
	year = {2007}
}
@article{Redmon2016,
	abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to per- form detection. Instead, we frame object detection as a re- gression problem to spatially separated bounding boxes and associated class probabilities. A single neural network pre- dicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detec- tors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations ofobjects. It outperforms other de- tection methods, including DPM and R-CNN, when gener- alizing from natural images to other domains like artwork.},
	archivePrefix = {arXiv},
	arxivId = {1506.02640},
	author = {Redmon, Joseph; Santosh Divvala; Ross Girshick; Ali Farhadi},
	doi = {10.1109/CVPR.2016.91},
	eprint = {1506.02640},
	file = {:C\:/Users/PabloGod/Downloads/yolo_1.pdf:pdf},
	isbn = {978-1-4673-8851-1},
	issn = {01689002},
	journal = {CVPR 2016},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	pmid = {27295650},
	title = {{YOLO: You Only Look Once - Unified, Real-Time Object Detecion}},
	year = {2016}
}
@misc{Solawetz2020,
	author = {Solawetz, Jacob},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{YOLO v5.0: How to Train A Custom Object Detection Model}},
	url = {https://towardsdatascience.com/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208},
	year = {2020}
}
@article{Zaarane2020,
	abstract = {The focus of this paper is inter-vehicles distance measurement which is a very important and challenging task in image processing domain. Where it is used in several systems such as Driving Safety Support Systems (DSSS), autonomous driving and traffic mobility. In the current paper, we propose an inter-vehicle distance measurement system for self-driving based on image processing. The proposed system uses two cameras mounted as one stereo camera, in the hosting vehicle behind the rear-view mirror. The detection of vehicles is performed first in a single camera using a recent powerful work from the literature. Then, the same vehicle is detected in the image captured by the second camera using template matching technique. Thus, the inter-vehicle distance is calculated using a simple method based on the position of the vehicle in both cameras, geometric derivations and additional technical data such as distance between the cameras and some other specific angles (e.g. the cameras view field angle). The results of the extensive experiments showed the high accuracy of the proposed method compared to the previous works from literature and it allows to measure efficiently the distances between the vehicles and the hosting vehicle. In addition, this method could be used in several systems of various domains in real time regardless of the object types. The experiments results were done on a Hardware Processor System (HPS) located in a VEEK-MT2S provided by TERASIC.},
	author = {Zaarane, Abdelmoghit and Slimani, Ibtissam and {Al Okaishi}, Wahban and Atouf, Issam and Hamdoun, Abdellatif},
	doi = {10.1016/j.array.2020.100016},
	file = {:C\:/Users/PabloGod/Downloads/zaarane2020.pdf:pdf},
	issn = {25900056},
	journal = {Array},
	mendeley-groups = {Thesis/Thesis 2},
	title = {{Distance measurement system for autonomous vehicles using stereo camera}},
	year = {2020}
}
@article{Redmon2018,
	abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320 × 320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 AP 50 in 51 ms on a Titan X, compared to 57.5 AP 50 in 198 ms by RetinaNet, similar performance but 3.8× faster. As always, all the code is online at https://pjreddie.com/yolo/.},
	author = {Redmon, Joseph and Farhadi, Ali},
	file = {:C\:/Users/PabloGod/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon, Farhadi - 2018 - YOLO v3.0.pdf:pdf},
	journal = {Tech report},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{YOLO v3.0: An Incremental Improvement}},
	year = {2018}
}
@article{Redmon2017,
	abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Us-ing a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster R-CNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on ob-ject detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. YOLO9000 predicts detections for more than 9000 different object categories, all in real-time.},
	archivePrefix = {arXiv},
	arxivId = {1612.08242},
	author = {Redmon, Joseph and Farhadi, Ali},
	doi = {10.1142/9789812771728_0012},
	eprint = {1612.08242},
	file = {:C\:/Users/PabloGod/Downloads/YOLO9000.pdf:pdf},
	isbn = {1879-2057 (Electronic)\n0001-4575 (Linking)},
	issn = {0146-4833},
	journal = {CVPR 2017},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	pages = {9},
	pmid = {23021419},
	title = {{YOLO v2.0: YOLO9000 - Better, Faster, Stronger}},
	url = {https://pjreddie.com/media/files/papers/YOLO9000.pdf},
	year = {2017}
}
@book{Callister2014,
	abstract = {Building on the extraordinary success of eight best-selling editions, Callister's new Ninth Edition of Materials Science and Engineering continues to promote student understanding of the three primary types of materials (metals, ceramics, and polymers) and composites, as well as the relationships that exist between the structural elements of materials and their properties. This edition is again supported by WileyPLUS, an integrated online learning environment, (when ordered as a package by an instructor). Also available is a redesigned version of Virtual Materials Science and Engineering (VMSE). This resource contains interactive simulations and animations that enhance the learning of key concepts in materials science and engineering (e.g., crystal structures, crystallographic planes/directions, dislocations) and, in addition, a comprehensive materials property database.},
	author = {Callister, William D. and {Callister Jr.}, William D. and Rethwisch, David G.},
	edition = {9th},
	file = {:C\:/Users/PabloGod/Downloads/Materials Science and Engineering An Introduction,9th Edition.pdf:pdf},
	isbn = {978-1-118-31922-2},
	keywords = {callister,engineering,enginerring,materials,science},
	mendeley-groups = {Thesis/Thesis 2},
	mendeley-tags = {callister,engineering,materials},
	pages = {936},
	publisher = {Willey},
	title = {{Materials Science and Engineering}},
	url = {https://www.wiley.com/en-gb/Materials+Science+and+Engineering%2C+9th+Edition+SI+Version-p-9781118319222},
	year = {2014}
}

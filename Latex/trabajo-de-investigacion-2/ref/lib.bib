@misc{bochkovskiy2020yolov4,
	abstract = {There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets.},
	archivePrefix = {arXiv},
	arxivId = {cs.CV/2004.10934},
	author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
	eprint = {2004.10934},
	keywords = {Computer Vision and Pattern Recognition,computer vision,yolo,yolo segmentation,yolo v2,yolov2,yolov3,yolov4},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	mendeley-tags = {computer vision,yolo,yolo segmentation,yolo v2,yolov2,yolov3,yolov4},
	pages = {17},
	primaryClass = {cs.CV},
	title = {{YOLO v4.0: Optimal Speed and Accuracy of Object Detection}},
	url = {https://arxiv.org/abs/2004.10934},
	year = {2020}
}
@phdthesis{DiazVergara2020,
	abstract = {Este trabajo de investigaci{\'{o}}n aborda el proceso cr{\'{i}}tico de clasificaci{\'{o}}n de truchas. Actualmente, llevados a cabo de forma manual en la Laguna de Paucarcocha. Este trabajo busca reducir la mortandad y aumentar la eficiencia del proceso. Elaborar el dise{\~{n}}o conceptual de la m{\'{a}}quina que puede automatizar el proceso es primordial. Se sigue la metodolog{\'{i}}a de dise{\~{n}}o VDI. Las conclusiones detallan la selecci{\'{o}}n del mejor dise{\~{n}}o conceptual de tres propuestos.},
	author = {{D{\'{i}}az Vergara}, Pablo},
	keywords = {clasification machine,counter machine,fish,fish segmentation,trout,truchas},
	mendeley-groups = {Thesis/Thesis 2},
	mendeley-tags = {clasification machine,counter machine,fish,fish segmentation,trout,truchas},
	pages = {79},
	school = {Pontificia Universidad Cat{\'{o}}lica del Per{\'{u}}},
	title = {{Dise{\~{n}}o conceptual de clasificadora y contadora de truchas arco{\'{i}}ris (Oncorhynchus mykiss) de 10 a 20 cent{\'{i}}metros para la crianza de truchas en la Laguna de Paucarcocha}},
	year = {2020}
}
@article{Fry1970,
	abstract = { Cruising speed at 10 C of rainbow trout 4–100 g was measured in a rotating chamber and found to vary as weight 0.13 . Weight varied as length 2.91 , so that swimming speed was dependent on length 0.4 , close to the relation found for other salmonids by other authors. A 10-g fish could swim at approximately 9 body lengths (L) sec −1 whereas at 100 g the cruising speed was 5.5 L sec −1 . By extrapolation the rate at 1000 g was 3 L sec −1 . },
	author = {Fry, F. E. J. and Cox, E. T.},
	doi = {10.1139/f70-111},
	issn = {0015-296X},
	journal = {Journal of the Fisheries Research Board of Canada},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{A Relation of Size to Swimming Speed in Rainbow Trout}},
	year = {1970}
}
@article{OatesDavidW.KringsLisaM.Ditz1993,
	abstract = {This manual is designed for use in the field to help conservation officers identify fish that have been filleted or skinned. Many North American freshwater gamefish and those caught by commercial fishermen are included. Our goal was to collect six fish of each species for measurement purposes. Several states and provinces in- cluding Alaska, Colorado, Florida, Idaho, Iowa, Michigan, Missouri, Nebraska, New York, Ontario, Saskatchewan, Texas, Virginia, Washington, Washington D.C., Wisconsin and Wyoming furnished samples. Fish may vary from loca- tion to location; these differences were not corrected for in this manual. For identification of fish, we will first examine fillets. Fish fillets, in most connotations, are of a fish skinned and cut along one side of the vertebrae. Two fillets (right and left side) are found on an individual fish (two left sides equal two fish, not one). Identification is much easier if the fish is scaled (number of scales may be counted vertically or horizontally) or if ribs are kept with the fillets. Some states and provinces require a one-inch patch of scales to be retained with each fillet. If this skin is removed, you have an illegal, unidentified fish. Some groups of fishes look so much alike that a close examination of scales or a laboratory analysis of flesh is necessary for identification. Shape of fillet, color and rib numbers can vary from species to species. Patterns on scales differ between species and can be used like human fingerprints. Many people fillet fish differently, and pieces can be fit together if necessary. Larger fillets may be cut up into smaller sections, but with smaller fish, the fillet is frequently kept whole. Can fillets be identified? Using an electrophoresis technique, some fish species have been identified by flesh alone. This can take agreat deal of time and many forensic laboratories are not equipped or able to perform this service. Very little research, except for identificationof larval fish, has examined the use of muscle segments or myotomes. A study in France by Blin, Balea and Prudhomme (1953) examined cross-sections of major fish sold at the market place. Cross-sections just behind the head (the end of sternum), at the tip of the anus and midway between anus and tail were taken. This comparison was taken for some of the fish examined and identification can be made to families. Can these fillets be identified without employing any fancy scientific equipment? For many species, the answer is yes. This manual was designed to aid in this task.},
	author = {{Oates, David W., Krings, Lisa M., Ditz}, Karen L.},
	journal = {Other Publications in Wildlife Management. Paper 13.},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{Field Manual for the Identification of Selected North American Freshwater Fish by Fillets and Scales}},
	year = {1993}
}
@book{Pahl2007,
	abstract = {Engineering design must be carefully planned and systematically executed. In particular, engineering design methods must integrate the many different aspects of designing and the priorities of the end-user. Engineering Design (3rd edition) describes a systematic approach to engineering design. The authors argue that such an approach, applied flexibly and adapted to a particular task, is essential for successful product development. The design process is first broken down into phases and then into distinct steps, each with its own working methods. The third edition of this internationally-recognised text is enhanced with new perspectives and the latest thinking. These include extended treatment of product planning; new sections on organisation structures, simultaneous engineering, leadership and team behaviour; and updated chapters on quality methods and estimating costs. New examples have been added and existing ones extended, with additions on design to minimise wear, design for recycling, mechanical connections, mechatronics, and adaptronics.},
	address = {London},
	author = {Pahl, Gerhard and Beitz, Wolfgang and Feldhusen, J{\"{o}}rg and Grote, Karl-Heinrich},
	doi = {10.1007/978-1-84628-319-2},
	edition = {3},
	isbn = {978-1-84628-318-5},
	mendeley-groups = {Thesis,Thesis/Thesis1,Thesis/Thesis 2},
	pages = {617},
	publisher = {Springer London},
	title = {{Engineering Design}},
	url = {http://link.springer.com/10.1007/978-1-84628-319-2},
	year = {2007}
}
@article{Redmon2018,
	abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320 × 320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 AP 50 in 51 ms on a Titan X, compared to 57.5 AP 50 in 198 ms by RetinaNet, similar performance but 3.8× faster. As always, all the code is online at https://pjreddie.com/yolo/.},
	author = {Redmon, Joseph and Farhadi, Ali},
	journal = {Tech report},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{YOLO v3.0}},
	year = {2018}
}
@article{Redmon2017,
	abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Us-ing a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster R-CNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on ob-ject detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. YOLO9000 predicts detections for more than 9000 different object categories, all in real-time.},
	archivePrefix = {arXiv},
	arxivId = {1612.08242},
	author = {Redmon, Joseph and Farhadi, Ali},
	doi = {10.1142/9789812771728_0012},
	eprint = {1612.08242},
	isbn = {1879-2057 (Electronic)\n0001-4575 (Linking)},
	issn = {0146-4833},
	journal = {Cvpr2017},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	pmid = {23021419},
	title = {{YOLO v2.0}},
	year = {2017}
}
@article{Redmon2016,
	abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to per- form detection. Instead, we frame object detection as a re- gression problem to spatially separated bounding boxes and associated class probabilities. A single neural network pre- dicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detec- tors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations ofobjects. It outperforms other de- tection methods, including DPM and R-CNN, when gener- alizing from natural images to other domains like artwork.},
	archivePrefix = {arXiv},
	arxivId = {1506.02640},
	author = {Redmon, Joseph; Santosh Divvala; Ross Girshick; Ali Farhadi},
	doi = {10.1109/CVPR.2016.91},
	eprint = {1506.02640},
	isbn = {978-1-4673-8851-1},
	issn = {01689002},
	journal = {Cvpr},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	pmid = {27295650},
	title = {{(YOLO) You Only Look Once}},
	year = {2016}
}
@misc{Solawetz2020,
	author = {Solawetz, Jacob},
	mendeley-groups = {Thesis,Thesis/Thesis 2},
	title = {{YOLO v5.0: How to Train A Custom Object Detection Model}},
	url = {https://towardsdatascience.com/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208},
	year = {2020}
}
